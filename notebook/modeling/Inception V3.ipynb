{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks tried earlier didn't gave the best results. So, let's try running the Inception V3 network inspired by https://github.com/stratospark/food-101-keras/blob/master/Food%20Classification%20with%20Deep%20Learning%20in%20Keras.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import stat\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used image augmentation in modeling.py file we can use multiprocessing.pool to accelerate image augmentation during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup multiprocessing pool\n",
    "# Do this early, as once images are loaded into memory there will be Errno 12\n",
    "# http://stackoverflow.com/questions/14749897/python-multiprocessing-memory-usage\n",
    "import multiprocessing as mp\n",
    "\n",
    "num_processes = 6\n",
    "pool = mp.Pool(processes=num_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original code loads all the data in the memory in one go, instead we are interested in loading the data in batches as we are working on a much smaller RAM size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import math\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "n_classes = 101\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = Dropout(.4)(x)\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(n_classes, init='glorot_uniform', W_regularizer=l2(.0005), activation='softmax')(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "opt = SGD(lr=.01, momentum=.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../../model/model4.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('../../logs/model4.log')\n",
    "\n",
    "def schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return .01\n",
    "    elif epoch < 28:\n",
    "        return .002\n",
    "    else:\n",
    "        return .0004\n",
    "lr_scheduler = LearningRateScheduler(schedule)\n",
    "\n",
    "# mixing the old code into GoogleNet\n",
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    zoom_range=[.8, 1],\n",
    "    channel_shift_range=30,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../../data/raw/food-101/smallersample/train/',  # this is the target directory\n",
    "    target_size=(299, 299),  # all images will be resized to 200x200\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    class_mode='categorical')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '../../data/raw/food-101/smallersample/test/',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=25250 // batch_size,\n",
    "#     nb_val_samples=X_test.shape[0],\n",
    "    steps_per_epoch=75750 // batch_size,\n",
    "#     samples_per_epoch=X_train.shape[0],\n",
    "    epochs=32,\n",
    "    callbacks=[lr_scheduler, csv_logger, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

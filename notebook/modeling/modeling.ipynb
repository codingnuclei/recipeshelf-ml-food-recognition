{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the different machine learning models on which the training data of the <i>food-101</i> dataset will be trained on. Algorithms with different complexities will be used here. Its always a good practice to start with simplest model and later trying complex ones. But before we get our hands dirty with modeling, one more step lies between EDA and modeling which is Feature Engineering. In a usual scenario, feature engineering should get its separate notebook but because the dataset is already clean, images are already arranged in proper folders, all food items have 1000 images(except for one data object as seen in EDA), and data is well split into training and test set so, there is not much to do in feature engineering. Also, if we have to make some changes in the dataset it might be based on the model we choose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the first model.\n",
    "# Support Vector Machine \n",
    "\n",
    "Support vector machine is discriminative classifier formally defined by a separating hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>SVM</i> is one of the simples models that we can you for classification. Images of different size could impact the learning of <i>SVM</i>. However, this is just an assumption. To see if this assumption holds we can train SVM on 2 datasets and evaluate the performance. To achieve this let's create a copy dataset where all the images are stored as square and of size <b>300x300</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the rectangular images to square can be achieved through two ways. Either by shrinking the dimensions or cutting them out. Resizing the dimension will keep all the information but will move the image away from real world example. For example, let's see how the smallest image in the dataset will look like if we resize it to be square. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Original Image</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image = Image.open('../../data/raw/food-101/images/macarons/3247436.jpg')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Resized Image</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Taking square root of the length * breath\n",
    "sqrWidth = np.ceil(np.sqrt(image.size[0] * image.size[1])).astype(int) \n",
    "im_resize = image.resize((sqrWidth, sqrWidth))\n",
    "plt.imshow(im_resize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite bad but still holds the information about the food. Let's see what happens when we cut the extra dimensions to make the image square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new square white image with dimenion equal to smaller side of original image\n",
    "# then paste the original image over the white image\n",
    "def make_square(image, max_size=600, fill_color=(0, 0, 0, 0)):\n",
    "    x, y = image.size\n",
    "    size = min(max_size, x, y)\n",
    "    new_im = Image.new('RGB', (size, size), fill_color)\n",
    "    new_im.paste(image, (int((size - x) / 2), int((size - y) / 2)))\n",
    "    return new_im\n",
    "\n",
    "new_image = make_square(image)\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks more like a real image, infact this image removes noise from the original image. However, we lose information while cropping the image. \n",
    "\n",
    "For the later method of cropping an image we can do a little variation and create a new kind of square image. Instead of using the smaller side of the image, we can use the longer one and fill the extra space with black or white color to generate a square image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new square white image with dimenion equal to smaller side of original image\n",
    "# then paste the original image over the white image\n",
    "def make_big_square(image, min_size=256, fill_color=(0, 0, 0)):\n",
    "    x, y = image.size\n",
    "    size = max(min_size, x, y)\n",
    "    new_im = Image.new('RGB', (size, size), fill_color)\n",
    "    new_im.paste(image, (int((size - x) / 2), int((size - y) / 2)))\n",
    "    return new_im\n",
    "\n",
    "new_image = make_big_square(image)\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This keeps all the information and convert the image to a square but also adds a lot more information. We don't know yest, whether this helps with learning or not. We can create new dataset of images in this format as well to compare performance of algorithm on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the resized image, shrining the longer dimension up to a certain length makes sense. If ratio of dimension is very high then the resizing can be far from realism. Let's see how many of the images in the dataset have ratio of more than 2:1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "path = '../../data/raw/food-101/images'\n",
    "\n",
    "imageCount = 0\n",
    "fileNameList = []\n",
    "\n",
    "for r, d, f in tqdm(os.walk(path)):\n",
    "    for file in f:\n",
    "        fileName = os.path.join(r, file)\n",
    "        image = Image.open(fileName)\n",
    "        # dividing the longer side of image with the smaller one\n",
    "        ratio = (max(image.size[0],image.size[1]) / min(image.size[0],image.size[1])) \n",
    "        if(ratio >= 2):\n",
    "            fileNameList.append(fileName)\n",
    "            imageCount += 1\n",
    "\n",
    "print(\"Number of images with ratio more than 2:1 are-\" + str(imageCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 47 images which have a ratio of more than 2:1, which is nothing compared to the total of 100999 images. Let's display 3 images from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as Images, display\n",
    "display(Images(filename=fileNameList[0]))\n",
    "display(Images(filename=fileNameList[21]))\n",
    "display(Images(filename=fileNameList[45]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 47 images contains a lot of false images as well. Let's take a look at false images. But because the images are very few in number we don't need to delete anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Images(filename=fileNameList[1]))\n",
    "display(Images(filename=fileNameList[17]))\n",
    "display(Images(filename=fileNameList[28]))\n",
    "display(Images(filename=fileNameList[29]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, this is good that only 47 images have dimension ratio of more than 2:1 but we don't know how many images are rectangle. To do the performance check of how different algorithms behave with different image sizes and scaling, we need to have a good quantity of images with rectangle shape. Let's count the number of images which are rectangle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/raw/food-101/images'\n",
    "\n",
    "rectangleImageCount = 0\n",
    "\n",
    "for r, d, f in tqdm(os.walk(path)):\n",
    "    for file in f:\n",
    "        fileName = os.path.join(r, file)\n",
    "        image = Image.open(fileName)\n",
    "        if(image.size[0] != image.size[1]):\n",
    "            rectangleImageCount += 1\n",
    "\n",
    "print(\"Number of rectangle images are: \" + str(rectangleImageCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 38793 images which are rectangle in the dataset, which is 38.4%. This number is high enough to see the change in learning performance based on different reshaping techniques. Let's start with creating first datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageShrink\n",
    "First dataset contains all square images achieved by shrinking the longer dimension to match the shorter one. We made a copy of data set and will now replace each rectangular image with a square in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/raw/food-101/imagesShrink'\n",
    "\n",
    "for r, d, f in tqdm(os.walk(path)):\n",
    "    for file in f:\n",
    "        fileName = os.path.join(r, file)\n",
    "        image = Image.open(fileName)\n",
    "        # Finding the shorter dimension\n",
    "        shorterDimension = min(image.size[0],image.size[1])\n",
    "        im_resize = image.resize((shorterDimension, shorterDimension))\n",
    "        # Replacing the original images with resized one.\n",
    "        im_resize.save(fileName, 'JPEG' )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if that worked. Displaying a random rectangular image from both directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Images(filename='../../data/raw/food-101/images/apple_pie/693210.jpg'))\n",
    "display(Images(filename='../../data/raw/food-101/imagesShrink/apple_pie/693210.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. Moving onto creating another dataset with longer length cropped to fit the square size.\n",
    "\n",
    "### ImageCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCrop = '../../data/raw/food-101/imagesCrop/'\n",
    "\n",
    "for r, d, f in tqdm(os.walk(pathCrop)):\n",
    "    for file in f:\n",
    "        fileName = os.path.join(r, file)\n",
    "        image = Image.open(fileName)\n",
    "        # cropping the image using the make_square function used earlier\n",
    "        new_image = make_square(image)\n",
    "        # Replacing the original images with resized one.\n",
    "        new_image.save(fileName, 'JPEG' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to remember:\n",
    "* images where we will lose the information if we crop to make it rectangular\n",
    "* using an algorithm to find the important part of food image which can be used to check the performance as well specially for cropped images.\n",
    "* Checking performance with or without data augmentation\n",
    "* after making it square, check performance with or without making all images of same size\n",
    "* use 5 different classifier atleast to know the performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

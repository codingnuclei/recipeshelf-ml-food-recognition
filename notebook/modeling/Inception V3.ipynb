{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks tried earlier didn't gave the best results. So, let's try running the Inception V3 network inspired by https://github.com/stratospark/food-101-keras/blob/master/Food%20Classification%20with%20Deep%20Learning%20in%20Keras.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import stat\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used image augmentation in modeling.py file we can use multiprocessing.pool to accelerate image augmentation during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original code loads all the data in the memory in one go, instead we are interested in loading the data in batches as we are working on a much smaller RAM size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import math\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "n_classes = 101\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=(299, 299, 3)))\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(8, 8))(x)\n",
    "x = Dropout(.4)(x)\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(n_classes, init='glorot_uniform', W_regularizer=l2(.0005), activation='softmax')(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "opt = SGD(lr=.01, momentum=.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='../../model/model4.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('../../logs/model4.log')\n",
    "\n",
    "def schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return .01\n",
    "    elif epoch < 28:\n",
    "        return .002\n",
    "    else:\n",
    "        return .0004\n",
    "lr_scheduler = LearningRateScheduler(schedule)\n",
    "\n",
    "# mixing the old code into GoogleNet\n",
    "# original sixe of the batch size was 64 but due to the limitation of the GPU memory the batch size is decreased. \n",
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    zoom_range=[.8, 1],\n",
    "    channel_shift_range=30,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../../data/raw/food-101/smallersample/train/',  # this is the target directory\n",
    "    target_size=(299, 299),  # all images will be resized to 299x299\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    class_mode='categorical')  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '../../data/raw/food-101/smallersample/test/',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=25250 // batch_size,\n",
    "#     steps_per_epoch=75750 // batch_size,\n",
    "#     epochs=32,\n",
    "#     callbacks=[lr_scheduler, csv_logger, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code works fine but is hard to train on the GPUs I have i.e 1070M due to heating issues and 980Ti due to the small memory size. Let's try to run the code on Goggle colab or any other platform like AWS Sagemaker.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Model Evaluation</h4>\n",
    "\n",
    "After training the code on Google colab. We have weights of the trained model. Let's load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../../model/model4.08-0.67.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make prediction for an image, we need to know what is the id of the images. Going by the assumption that model trained on colab used the same ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as Images, display\n",
    "\n",
    "display(Images(filename=\"../../data/raw/food-101/images/fried_rice/260614.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the above image of fried rice and make prediction. As can be seen from cell above, the predicted id should be 44. But before that we need to convert the image data such that it could be understood by th model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "\n",
    "# to check if the image is of shape 299 x 299. if not then resize to this shape. \n",
    "min_side=299\n",
    "img_arr = img.imread(\"../../data/raw/food-101/images/fried_rice/260614.jpg\")\n",
    "img_arr_rs = img_arr\n",
    "\n",
    "try:\n",
    "    w, h, _ = img_arr.shape\n",
    "    if w < min_side:\n",
    "        wpercent = (min_side/float(w))\n",
    "        hsize = int((float(h)*float(wpercent)))\n",
    "        #print('new dims:', min_side, hsize)\n",
    "        img_arr_rs = imresize(img_arr, (min_side, hsize))\n",
    "        resize_count += 1\n",
    "    elif h < min_side:\n",
    "        hpercent = (min_side/float(h))\n",
    "        wsize = int((float(w)*float(hpercent)))\n",
    "        #print('new dims:', wsize, min_side)\n",
    "        img_arr_rs = imresize(img_arr, (wsize, min_side))\n",
    "        resize_count += 1\n",
    "except:\n",
    "    print('Skipping bad image')\n",
    "    \n",
    "# cropping the image to be 299 x 299\n",
    "imageData = center_crop(img_arr_rs, (299, 299))\n",
    "# changing the shape of the imageData to fit the prediction\n",
    "imageData = imageData[np.newaxis,:,:,:]\n",
    "\n",
    "y_pred = model.predict(imageData)\n",
    "preds = np.argmax(y_pred, axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yipppeeee! we got index 44 which is the index of fried rice. So it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to evaluate the test set using multiple crops. This is expected to raise the accuracy by 5% compared to single crop evaluation. It is common to use the following crops: Upper Left, Upper Right, Lower Left, Lower Right, Center. We also take the same crops on the image flipped left to right, creating a total of 10 crops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(x, center_crop_size, **kwargs):\n",
    "    centerw, centerh = x.shape[0]//2, x.shape[1]//2\n",
    "    halfw, halfh = center_crop_size[0]//2, center_crop_size[1]//2\n",
    "    return x[centerw-halfw:centerw+halfw+1,centerh-halfh:centerh+halfh+1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_10_crop(img, top_n=5, plot=False, preprocess=True, debug=False):\n",
    "    flipped_X = np.fliplr(img)\n",
    "    crops = [\n",
    "        img[:299,:299, :], # Upper Left\n",
    "        img[:299, img.shape[1]-299:, :], # Upper Right\n",
    "        img[img.shape[0]-299:, :299, :], # Lower Left\n",
    "        img[img.shape[0]-299:, img.shape[1]-299:, :], # Lower Right\n",
    "        center_crop(img, (299, 299)),\n",
    "        \n",
    "        flipped_X[:299,:299, :],\n",
    "        flipped_X[:299, flipped_X.shape[1]-299:, :],\n",
    "        flipped_X[flipped_X.shape[0]-299:, :299, :],\n",
    "        flipped_X[flipped_X.shape[0]-299:, flipped_X.shape[1]-299:, :],\n",
    "        center_crop(flipped_X, (299, 299))\n",
    "    ]\n",
    "    if preprocess:\n",
    "        crops = [preprocess_input(x.astype('float32')) for x in crops]\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2, 5, figsize=(10, 4))\n",
    "        ax[0][0].imshow(crops[0])\n",
    "        ax[0][1].imshow(crops[1])\n",
    "        ax[0][2].imshow(crops[2])\n",
    "        ax[0][3].imshow(crops[3])\n",
    "        ax[0][4].imshow(crops[4])\n",
    "        ax[1][0].imshow(crops[5])\n",
    "        ax[1][1].imshow(crops[6])\n",
    "        ax[1][2].imshow(crops[7])\n",
    "        ax[1][3].imshow(crops[8])\n",
    "        ax[1][4].imshow(crops[9])\n",
    "    \n",
    "    y_pred = model.predict(np.array(crops))\n",
    "    preds = np.argmax(y_pred, axis=1)\n",
    "    top_n_preds= np.argpartition(y_pred, -top_n)[:,-top_n:]\n",
    "    if debug:\n",
    "        print('Top-1 Predicted:', preds)\n",
    "        print('Top-5 Predicted:', top_n_preds)\n",
    "    return preds, top_n_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it worked on this pad thai image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as Images, display\n",
    "\n",
    "display(Images(filename=\"../../data/abc.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incoming image could be of any size, we need a function that convert it to appropriate size for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as matimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "# filePath = '../../data/abc.jpg'\n",
    "allowedAspectratio = 1.3\n",
    "minAllowedSize = 299\n",
    "\n",
    "def imageResize(filePath):\n",
    "    img = Image.open(filePath)\n",
    "    resizeSize = 400\n",
    "    width, height = img.size\n",
    "    mainImageToggle = True\n",
    "    \n",
    "    if(height > width):\n",
    "        if(width < minAllowedSize):\n",
    "            wpercent = (resizeSize/float(img.size[0]))\n",
    "            hsize = int((float(img.size[1])*float(wpercent)))\n",
    "            img = img.resize((resizeSize, hsize), PIL.Image.ANTIALIAS)\n",
    "            img.save('../../data/updatedImage.jpg')\n",
    "            im = Image.open('../../data/updatedImage.jpg')\n",
    "            width, height = im.size   # Get dimensions\n",
    "            mainImageToggle = False\n",
    "        if((height/width) > allowedAspectratio):\n",
    "            extraHeight = height - (width * 1.3)\n",
    "            top = extraHeight/2\n",
    "            bottom = height - extraHeight/2\n",
    "            if(mainImageToggle):\n",
    "                img = img.crop((0, top, width, bottom))\n",
    "                img.save('../../data/updatedImage.jpg')\n",
    "            else:\n",
    "                im = im.crop((0, top, width, bottom))\n",
    "                im.save('../../data/updatedImage.jpg')\n",
    "        else:\n",
    "            img.save('../../data/updatedImage.jpg')\n",
    "    else:\n",
    "        if(height < minAllowedSize):\n",
    "            hpercent = (resizeSize/float(img.size[1]))\n",
    "            wsize = int((float(img.size[0])*float(hpercent)))\n",
    "            img = img.resize((wsize, resizeSize), PIL.Image.ANTIALIAS)\n",
    "            img.save('../../data/updatedImage.jpg')\n",
    "            im = Image.open('../../data/updatedImage.jpg')\n",
    "            width, height = im.size   # Get dimensions\n",
    "            mainImageToggle = False\n",
    "        if((width/height) > allowedAspectratio):\n",
    "            extraWidth = width - (height * 1.3)\n",
    "            left = extraWidth/2\n",
    "            right = width - extraWidth/2\n",
    "            if(mainImageToggle):\n",
    "                img = img.crop((left, 0, right, height))\n",
    "                img.save('../../data/updatedImage.jpg')\n",
    "            else:\n",
    "                im = im.crop((left, 0, right, height))\n",
    "                im.save('../../data/updatedImage.jpg')\n",
    "        else:\n",
    "            img.save('../../data/updatedImage.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a prediction now and get top-1 and top-5 accuracy for 10 cropped images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/raw/food-101/smallersample/newtest/baby_back_ribs/112142.jpg'\n",
    "imageResize(path)\n",
    "img_arr = matimg.imread(\"../../data/updatedImage.jpg\")\n",
    "prediction, topNPrediction = predict_10_crop(img_arr, top_n=5, plot=True, preprocess=False, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We got the predictions. Let's see what is the most common prediction in all 10 crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.bincount(prediction)\n",
    "mostCommonPrediction = np.argmax(counts)\n",
    "print(mostCommonPrediction)\n",
    "\n",
    "labelDictonary = train_generator.class_indices\n",
    "print(list(labelDictonary.keys())[list(labelDictonary.values()).index(mostCommonPrediction)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test so that, we can make the performance analysis on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to split dataset into train and test folders\n",
    "\n",
    "from shutil import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "def prepare_data(filepath, src, dest):\n",
    "    classes_images = defaultdict(list)\n",
    "    with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "            \n",
    "    for food in classes_images.keys():\n",
    "        print(\"\\nCopying images into \",food)\n",
    "        if not os.path.exists(os.path.join(dest,food)):\n",
    "            os.makedirs(os.path.join(dest,food))\n",
    "        for i in classes_images[food]:\n",
    "            copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "\n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare test data by copying images from food-101/images to food-101/test using the file test.txt\n",
    "print(\"Creating test data...\")\n",
    "prepare_data('../../data/raw/food-101/meta/test.txt', '../../data/raw/food-101/images', '../../data/raw/food-101/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the classes from the meta data file available from the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../data/raw/food-101/meta/classes.txt'\n",
    "\n",
    "with open(filename) as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "classList = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through each image and making a prediction. Also, as we already know the number of test images, we can setup 2 fixed sized numpy array. One 2D and other one 3D. First one will contain actual class along with guess for all 10 crops and most common value out of all 10 crop guesses. Second array contains the top 5 guess for all 10 crops for all 25250 test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.image as matimg\n",
    "import keras.backend as K\n",
    "\n",
    "path = '../../data/raw/food-101/test/'\n",
    "\n",
    "topNPred = 5\n",
    "topPred2D = np.zeros((25250,12))\n",
    "top5Pred3D = np.zeros((25250,10,topNPred))\n",
    "imageCount = 0\n",
    "\n",
    "for r, d, f in tqdm(os.walk(path)):\n",
    "    for file in f:\n",
    "        fileName = os.path.join(r, file)\n",
    "        className = fileName.split('/')[-1]\n",
    "        className = className.split('\\\\')[0]\n",
    "        try:\n",
    "            imageResize(fileName)\n",
    "            img_arr = matimg.imread(\"../../data/updatedImage.jpg\")\n",
    "            prediction, topNPrediction = predict_10_crop(img_arr, top_n=topNPred, plot=False, preprocess=False, debug=False)\n",
    "            \n",
    "            K.clear_session()\n",
    "            # populating the 2D array\n",
    "            topPred2D[imageCount][0] = classList.index(className) # actual class index from classes.txt file\n",
    "            topPred2D[imageCount][1:-1] = prediction # prediction for all 10 crops\n",
    "            counts = np.bincount(prediction) \n",
    "            mostCommonPrediction = np.argmax(counts)\n",
    "            topPred2D[imageCount][-1] = mostCommonPrediction # most common value among all 10 predictions\n",
    "        \n",
    "            top5Pred3D[imageCount] = topNPrediction\n",
    "        except:\n",
    "            print(fileName)\n",
    "            \n",
    "        \n",
    "        imageCount = imageCount + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the arrays to a hfd5 file under processed folder. hdf5 files reduce the data size considerably and reading or writing to the file is very fast. It will save us lot of time to load the data everytime when we do performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Address to store the HDF5 file \n",
    "hdf5Path = r'..\\..\\data\\processed\\predictions.hdf5'\n",
    "\n",
    "h5f = h5py.File(hdf5Path, 'w')\n",
    "h5f.create_dataset('topPred2D', data=topPred2D)\n",
    "h5f.create_dataset('top5Pred3D', data=top5Pred3D)\n",
    "h5f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the different machine learning models on which the training data of the <i>food-101</i> dataset will be trained on. Algorithms with different complexities will be used here. Its always a good practice to start with simplest model and later trying complex ones. But before we get our hands dirty with modeling, one more step lies between EDA and modeling which is Feature Engineering. In a usual scenario, feature engineering should get its separate notebook but because the dataset is already clean, images are already arranged in proper folders, all food items have 1000 images(except for one data object as seen in EDA), and data is well split into training and test set so, there is not much to do in feature engineering. Also, if we have to make some changes in the dataset it might be based on the model we choose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the first model.\n",
    "# Support Vector Machine \n",
    "\n",
    "Support vector machine is discriminative classifier formally defined by a separating hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>SVM</i> is one of the simples models that we can you for classification. Images of different size could impact the learning of <i>SVM</i>. However, this is just an assumption. To see if this assumption holds we can train SVM on 2 datasets and evaluate the performance. To achieve this let's create a copy dataset where all the images are stored as square and of size <b>300x300</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the rectangular images to square can be achieved through two ways. Either by shrinking the dimensions or cutting them out. Resizing the dimension will keep all the information but will move the image away from real world example. For example, let's see how the smallest image in the dataset will look like if we resize it to be square. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Original Image</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image = Image.open('../../data/raw/food-101/images/macarons/3247436.jpg')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Resized Image</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Taking square root of the length * breath\n",
    "sqrWidth = np.ceil(np.sqrt(image.size[0] * image.size[1])).astype(int) \n",
    "im_resize = image.resize((sqrWidth, sqrWidth))\n",
    "plt.imshow(im_resize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite bad but still holds the information about the food. Let's see what happens when we cut the extra dimensions to make the image square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new square white image with dimenion equal to smaller side of original image\n",
    "# then paste the original image over the white image\n",
    "def make_square(image, max_size=150, fill_color=(0, 0, 0, 0)):\n",
    "    x, y = image.size\n",
    "    size = min(max_size, x, y)\n",
    "    new_im = Image.new('RGBA', (size, size), fill_color)\n",
    "    new_im.paste(image, (int((size - x) / 2), int((size - y) / 2)))\n",
    "    return new_im\n",
    "\n",
    "new_image = make_square(image)\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks more like a real image, infact this image removes noise from the original image. However, we lose information while cropping the image. \n",
    "\n",
    "For the later method of cropping an image we can do a little variation and create a new kind of square image. Instead of using the smaller side of the image, we can use the longer one and fill the extra space with black or white color to generate a square image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new square white image with dimenion equal to smaller side of original image\n",
    "# then paste the original image over the white image\n",
    "def make_big_square(image, min_size=256, fill_color=(0, 0, 0)):\n",
    "    x, y = image.size\n",
    "    size = max(min_size, x, y)\n",
    "    new_im = Image.new('RGBA', (size, size), fill_color)\n",
    "    new_im.paste(image, (int((size - x) / 2), int((size - y) / 2)))\n",
    "    return new_im\n",
    "\n",
    "new_image = make_square(image)\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This keeps all the information and convert the image to square but adds lot more information. We don't know whether this helps with learning or not. We can create new dataset of images in this format as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to remember:\n",
    "* check the number of images with ratio more than 2:1\n",
    "* images where we will lose the information if we crop to make it rectangular\n",
    "* using an algorithm to find the important part of food image which can be used to check the performance as well\n",
    "* after making it square, check performance with or without making all images of same size\n",
    "* use 5 different classifier atleast to know the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
